{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68072c7f-e379-4918-8b1c-70a3433b7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from logging import getLogger\n",
    "import sys\n",
    "from data_utilis import Preprocessor_fairagent, GetInfo, split_data, split_test\n",
    "import daisy\n",
    "import importlib\n",
    "importlib.reload(daisy)\n",
    "from daisy.utils.loader import RawDataReader, Preprocessor\n",
    "from daisy.utils.splitter import TestSplitter, ValidationSplitter\n",
    "from daisy.utils.config import init_seed, init_config, init_logger\n",
    "from daisy.utils.metrics import MAP, NDCG, Recall, Precision, HR, MRR\n",
    "from daisy.utils.sampler import BasicNegtiveSampler, SkipGramNegativeSampler, UniqueNegativeSampler\n",
    "from daisy.utils.dataset import AEDataset, BasicDataset, CandidatesDataset, get_dataloader\n",
    "from daisy.utils.utils import get_history_matrix, get_ur, build_candidates_set, ensure_dir, get_inter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8812d9-1f66-403d-9909-5b1d0b85e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = init_config()\n",
    "\n",
    "''' init seed for reproducibility '''\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "''' init logger '''\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "logger.info(config)\n",
    "config['logger'] = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f781fc45-f3ec-4053-97b3-fa083bfd40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = config['save_path'] + config['version']\n",
    "ensure_dir(save_path)\n",
    "\n",
    "file_path = save_path + f'{config[\"dataset\"]}/'\n",
    "ensure_dir(file_path)\n",
    "\n",
    "saved_data_path = file_path + 'data/'\n",
    "ensure_dir(saved_data_path)\n",
    "\n",
    "saved_result_path = file_path + f'{config[\"algo_name\"]}/'\n",
    "ensure_dir(saved_result_path)\n",
    "\n",
    "saved_model_path = saved_result_path + 'model/'\n",
    "ensure_dir(saved_model_path)\n",
    "\n",
    "saved_rec_path = saved_result_path + 'rec_list/'\n",
    "ensure_dir(saved_rec_path)\n",
    "\n",
    "saved_metric_path = saved_result_path + 'metric/'\n",
    "ensure_dir(saved_metric_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1b30c02-f019-4210-9c18-4950fd09539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './origin_data/'\n",
    "origin_data = pd.read_csv(data_path + 'small_matrix.csv')\n",
    "origin_data = origin_data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "origin_data = origin_data.rename(columns={'user_id': config['UID_NAME'], 'video_id': config['IID_NAME'], 'watch_ratio': config['INTER_NAME']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c0e22a-cbeb-4625-b471-74a9041fba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>148</td>\n",
       "      <td>4381</td>\n",
       "      <td>6067</td>\n",
       "      <td>2020-07-05 05:27:48.378</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>0.722103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "      <td>11635</td>\n",
       "      <td>6100</td>\n",
       "      <td>2020-07-05 05:28:00.057</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>1.907377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>3650</td>\n",
       "      <td>22422</td>\n",
       "      <td>10867</td>\n",
       "      <td>2020-07-05 05:29:09.479</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>2.063311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>5263</td>\n",
       "      <td>4479</td>\n",
       "      <td>7908</td>\n",
       "      <td>2020-07-05 05:30:43.285</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593898e+09</td>\n",
       "      <td>0.566388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>8235</td>\n",
       "      <td>4602</td>\n",
       "      <td>11000</td>\n",
       "      <td>2020-07-05 05:35:43.459</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593899e+09</td>\n",
       "      <td>0.418364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676370</th>\n",
       "      <td>7162</td>\n",
       "      <td>9178</td>\n",
       "      <td>5315</td>\n",
       "      <td>37205</td>\n",
       "      <td>2020-09-01 20:06:35.984</td>\n",
       "      <td>20200901.0</td>\n",
       "      <td>1.598962e+09</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676371</th>\n",
       "      <td>7162</td>\n",
       "      <td>4988</td>\n",
       "      <td>10085</td>\n",
       "      <td>8167</td>\n",
       "      <td>2020-09-02 14:44:51.342</td>\n",
       "      <td>20200902.0</td>\n",
       "      <td>1.599029e+09</td>\n",
       "      <td>1.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676372</th>\n",
       "      <td>7162</td>\n",
       "      <td>7989</td>\n",
       "      <td>50523</td>\n",
       "      <td>49319</td>\n",
       "      <td>2020-09-03 08:45:01.474</td>\n",
       "      <td>20200903.0</td>\n",
       "      <td>1.599094e+09</td>\n",
       "      <td>1.024412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676373</th>\n",
       "      <td>7162</td>\n",
       "      <td>6534</td>\n",
       "      <td>2190</td>\n",
       "      <td>8000</td>\n",
       "      <td>2020-09-04 22:56:32.021</td>\n",
       "      <td>20200904.0</td>\n",
       "      <td>1.599231e+09</td>\n",
       "      <td>0.273750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676374</th>\n",
       "      <td>7162</td>\n",
       "      <td>6524</td>\n",
       "      <td>11909</td>\n",
       "      <td>7255</td>\n",
       "      <td>2020-09-05 00:32:09.154</td>\n",
       "      <td>20200905.0</td>\n",
       "      <td>1.599237e+09</td>\n",
       "      <td>1.641489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4494578 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user  item  play_duration  video_duration                     time  \\\n",
       "0          14   148           4381            6067  2020-07-05 05:27:48.378   \n",
       "1          14   183          11635            6100  2020-07-05 05:28:00.057   \n",
       "2          14  3650          22422           10867  2020-07-05 05:29:09.479   \n",
       "3          14  5263           4479            7908  2020-07-05 05:30:43.285   \n",
       "4          14  8235           4602           11000  2020-07-05 05:35:43.459   \n",
       "...       ...   ...            ...             ...                      ...   \n",
       "4676370  7162  9178           5315           37205  2020-09-01 20:06:35.984   \n",
       "4676371  7162  4988          10085            8167  2020-09-02 14:44:51.342   \n",
       "4676372  7162  7989          50523           49319  2020-09-03 08:45:01.474   \n",
       "4676373  7162  6534           2190            8000  2020-09-04 22:56:32.021   \n",
       "4676374  7162  6524          11909            7255  2020-09-05 00:32:09.154   \n",
       "\n",
       "               date     timestamp     label  \n",
       "0        20200705.0  1.593898e+09  0.722103  \n",
       "1        20200705.0  1.593898e+09  1.907377  \n",
       "2        20200705.0  1.593898e+09  2.063311  \n",
       "3        20200705.0  1.593898e+09  0.566388  \n",
       "4        20200705.0  1.593899e+09  0.418364  \n",
       "...             ...           ...       ...  \n",
       "4676370  20200901.0  1.598962e+09  0.142857  \n",
       "4676371  20200902.0  1.599029e+09  1.234848  \n",
       "4676372  20200903.0  1.599094e+09  1.024412  \n",
       "4676373  20200904.0  1.599231e+09  0.273750  \n",
       "4676374  20200905.0  1.599237e+09  1.641489  \n",
       "\n",
       "[4494578 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4decd41-3278-4538-9525-54dd678fdae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process data\n",
    "df = origin_data.copy()\n",
    "processor = Preprocessor_fairaget(config)\n",
    "df = processor.process(df)\n",
    "user_num, item_num, time_dict = processor.user_num, processor.item_num, processor.time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "828c5d93-b5b1-436e-b67b-1abef9afc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save data\n",
    "df.to_csv(saved_data_path + 'all_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5744b08-e103-4265-a9dc-06d0cc357e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user number: 1411  item number: 3317  interaction number: 1471862\n"
     ]
    }
   ],
   "source": [
    "# store information of user number and item number\n",
    "config['user_num'] = user_num\n",
    "config['item_num'] = item_num\n",
    "\n",
    "print(f\"user number: {user_num}  item number: {item_num}  interaction number: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2252ad93-d743-43de-b7c5-259083fbf466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train_base/30% train_rl/20 test/10% * 5 for each test stage.\n",
    "train_base_ids, train_rl_ids, test_ids = split_data(df, config['train_base_ratio'], config['train_rl_ratio'])\n",
    "train_base_set, train_rl_set, test_set = df.iloc[train_base_ids, :].copy(), df.iloc[train_rl_ids, :].copy(), df.iloc[test_ids, :].copy()\n",
    "test_df_list = split_test(test_set, config['test_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ebb04a-337c-4d73-b54b-75b7e4650d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Info:train_base---\n",
      "user number: 1411  item number: 1319\n",
      "len: 441559\n",
      "\n",
      "---Info:train_rl---\n",
      "len: 294372\n",
      "number of user: 1411\n",
      "number of new-user: 0\n",
      "number of item: 1916\n",
      "number of new-item: 676\n",
      "\n",
      "---Test period 0---\n",
      "len: 147186\n",
      "number of user: 1409\n",
      "number of new-user: 0\n",
      "number of item: 2070\n",
      "number of new-item: 351\n",
      "\n",
      "---Test period 1---\n",
      "len: 147186\n",
      "number of user: 1411\n",
      "number of new-user: 0\n",
      "number of item: 2135\n",
      "number of new-item: 254\n",
      "\n",
      "---Test period 2---\n",
      "len: 147186\n",
      "number of user: 1409\n",
      "number of new-user: 0\n",
      "number of item: 2118\n",
      "number of new-item: 296\n",
      "\n",
      "---Test period 3---\n",
      "len: 147186\n",
      "number of user: 1410\n",
      "number of new-user: 0\n",
      "number of item: 1827\n",
      "number of new-item: 233\n",
      "\n",
      "---Test period 4---\n",
      "len: 147187\n",
      "number of user: 1410\n",
      "number of new-user: 0\n",
      "number of item: 1578\n",
      "number of new-item: 188\n"
     ]
    }
   ],
   "source": [
    "# If there are new users, filter\n",
    "set_info = GetInfo(train_base_set,train_rl_set,test_df_list,config)\n",
    "set_info.get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df401b2-8eb6-4785-9732-25ff8c7031d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial warm and cold item list for training FairAgent and baselines.\n",
    "warm_item_list = train_base_set[config['IID_NAME']].unique()\n",
    "\n",
    "cold_item_list = list(set(df[config['IID_NAME']].unique()) - set(warm_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400b4a36-90a4-4698-82a5-596d7599a145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1316, 1317, 1318], dtype=int16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warm_item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e00ea68-5f2f-4976-88f0-891c53bf00d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221</td>\n",
       "      <td>0</td>\n",
       "      <td>29789</td>\n",
       "      <td>15034</td>\n",
       "      <td>2020-07-04 02:23:26.06</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593801e+09</td>\n",
       "      <td>1.981442</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221</td>\n",
       "      <td>1</td>\n",
       "      <td>33766</td>\n",
       "      <td>10600</td>\n",
       "      <td>2020-07-04 06:50:30.434</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593817e+09</td>\n",
       "      <td>3.185472</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>13598</td>\n",
       "      <td>9167</td>\n",
       "      <td>2020-07-05 00:00:49.448</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593878e+09</td>\n",
       "      <td>1.483364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9883</td>\n",
       "      <td>7200</td>\n",
       "      <td>2020-07-05 00:01:03.816</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593878e+09</td>\n",
       "      <td>1.372639</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>11541</td>\n",
       "      <td>11000</td>\n",
       "      <td>2020-07-05 00:01:40.379</td>\n",
       "      <td>20200705.0</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.049182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735926</th>\n",
       "      <td>640</td>\n",
       "      <td>1949</td>\n",
       "      <td>15111</td>\n",
       "      <td>8843</td>\n",
       "      <td>2020-07-31 05:51:36.332</td>\n",
       "      <td>20200731.0</td>\n",
       "      <td>1.596146e+09</td>\n",
       "      <td>1.708809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735927</th>\n",
       "      <td>995</td>\n",
       "      <td>91</td>\n",
       "      <td>11040</td>\n",
       "      <td>9100</td>\n",
       "      <td>2020-07-31 05:51:37.397</td>\n",
       "      <td>20200731.0</td>\n",
       "      <td>1.596146e+09</td>\n",
       "      <td>1.213187</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735928</th>\n",
       "      <td>1058</td>\n",
       "      <td>1951</td>\n",
       "      <td>8453</td>\n",
       "      <td>7267</td>\n",
       "      <td>2020-07-31 05:51:39.554</td>\n",
       "      <td>20200731.0</td>\n",
       "      <td>1.596146e+09</td>\n",
       "      <td>1.163204</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735929</th>\n",
       "      <td>700</td>\n",
       "      <td>1881</td>\n",
       "      <td>6940</td>\n",
       "      <td>6667</td>\n",
       "      <td>2020-07-31 05:51:39.708</td>\n",
       "      <td>20200731.0</td>\n",
       "      <td>1.596146e+09</td>\n",
       "      <td>1.040948</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735930</th>\n",
       "      <td>38</td>\n",
       "      <td>1934</td>\n",
       "      <td>7981</td>\n",
       "      <td>6567</td>\n",
       "      <td>2020-07-31 05:51:40.03</td>\n",
       "      <td>20200731.0</td>\n",
       "      <td>1.596146e+09</td>\n",
       "      <td>1.215319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735931 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  play_duration  video_duration                     time  \\\n",
       "0       1221     0          29789           15034   2020-07-04 02:23:26.06   \n",
       "1       1221     1          33766           10600  2020-07-04 06:50:30.434   \n",
       "2        602     2          13598            9167  2020-07-05 00:00:49.448   \n",
       "3          6     3           9883            7200  2020-07-05 00:01:03.816   \n",
       "4        164     4          11541           11000  2020-07-05 00:01:40.379   \n",
       "...      ...   ...            ...             ...                      ...   \n",
       "735926   640  1949          15111            8843  2020-07-31 05:51:36.332   \n",
       "735927   995    91          11040            9100  2020-07-31 05:51:37.397   \n",
       "735928  1058  1951           8453            7267  2020-07-31 05:51:39.554   \n",
       "735929   700  1881           6940            6667  2020-07-31 05:51:39.708   \n",
       "735930    38  1934           7981            6567   2020-07-31 05:51:40.03   \n",
       "\n",
       "              date     timestamp     label  rating  \n",
       "0       20200705.0  1.593801e+09  1.981442     1.0  \n",
       "1       20200705.0  1.593817e+09  3.185472     1.0  \n",
       "2       20200705.0  1.593878e+09  1.483364     1.0  \n",
       "3       20200705.0  1.593878e+09  1.372639     1.0  \n",
       "4       20200705.0  1.593879e+09  1.049182     1.0  \n",
       "...            ...           ...       ...     ...  \n",
       "735926  20200731.0  1.596146e+09  1.708809     1.0  \n",
       "735927  20200731.0  1.596146e+09  1.213187     1.0  \n",
       "735928  20200731.0  1.596146e+09  1.163204     1.0  \n",
       "735929  20200731.0  1.596146e+09  1.040948     1.0  \n",
       "735930  20200731.0  1.596146e+09  1.215319     1.0  \n",
       "\n",
       "[735931 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total_set = pd.concat([train_base_set, train_rl_set])\n",
    "train_total_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12c44b3a-789b-4e49-8e77-2336744914fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical interaction as ground-truth\n",
    "train_base_ur = get_ur(train_base_set)\n",
    "train_rl_ur = get_ur(train_rl_set)\n",
    "train_total_ur = get_ur(train_total_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71e76a48-4539-4ea8-b8ee-bc6b1c8bda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negtive sample for traininng backbone models\n",
    "config['train_ur'] = train_total_ur\n",
    "sampler = UniqueNegativeSampler(train_total_set, config)\n",
    "train_samples = sampler.sampling()\n",
    "train_dataset = BasicDataset(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be602b13-2c71-43fc-9d75-9f925f9f120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1221,    0, 1035],\n",
       "       [1221,    0,  851],\n",
       "       [1221,    0,  984],\n",
       "       [1221,    0, 1023],\n",
       "       [1221,    1,  899],\n",
       "       [1221,    1,  909],\n",
       "       [1221,    1,  767],\n",
       "       [1221,    1,  307],\n",
       "       [ 602,    2,  300],\n",
       "       [ 602,    2,  660],\n",
       "       [ 602,    2,  478],\n",
       "       [ 602,    2,  193],\n",
       "       [   6,    3,  480],\n",
       "       [   6,    3,  736],\n",
       "       [   6,    3,  771],\n",
       "       [   6,    3,  242],\n",
       "       [ 164,    4,  555],\n",
       "       [ 164,    4,  387],\n",
       "       [ 164,    4,  330],\n",
       "       [ 164,    4,  918]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_test = train_samples[:20]\n",
    "list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5311a16-68ff-4324-ba33-20fd05c28217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get candidate sets for testing\n",
    "test_u_all = []\n",
    "test_ucands_all = []\n",
    "test_ur_all = []\n",
    "for i in range(config['test_num']):\n",
    "    test_ur = get_ur(test_df_list[i])\n",
    "    test_u, test_ucands = build_candidates_set(test_ur, train_total_ur, config)\n",
    "    test_u_all.append(test_u)\n",
    "    test_ucands_all.append(test_ucands)\n",
    "    test_ur_all.append(test_ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22905133-120d-47ba-bc9b-e3dbfedb8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saved_data_path + 'warm_item_list.npy',warm_item_list)\n",
    "np.save(saved_data_path + 'cold_item_list.npy',cold_item_list)\n",
    "np.save(saved_data_path + 'train_base_samples.npy',train_samples)\n",
    "train_base_set.to_csv(saved_data_path + 'train_base_set.csv')\n",
    "np.save(saved_data_path + 'test_u_all.npy',test_u_all)\n",
    "np.save(saved_data_path + 'test_ucands_all.npy',test_ucands_all)\n",
    "np.save(saved_data_path + 'test_ur_all.npy',test_ur_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b36bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ur(ur, saved_data_path, saved_name):\n",
    "    ur_dict = {key: list(value) for key, value in ur.items()}\n",
    "    with open(saved_data_path + saved_name, 'w') as file:\n",
    "        json.dump(ur_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20de7f7d-f17f-4f5c-8787-713d727f955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get candidate set of train_rl to train FairAgent\n",
    "train_rl_u, train_rl_ucands = build_candidates_set(train_rl_ur, train_base_ur, config)\n",
    "train_total_ur = get_ur(train_total_set)\n",
    "\n",
    "# save_ur(train_base_ur, saved_data_path, 'train_base_ur.json')\n",
    "# save_ur(train_rl_ur, saved_data_path, 'train_rl_ur.json')\n",
    "save_ur(train_total_ur, saved_data_path, 'train_total_ur.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8721b951-f397-4c67-bd38-494b19cd7099",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saved_data_path + 'train_rl_u.npy',train_rl_u)\n",
    "np.save(saved_data_path + 'train_rl_ucands.npy',train_rl_ucands)\n",
    "np.save(saved_data_path + 'train_rl_ur.npy',train_rl_ur)\n",
    "\n",
    "train_rl_set.to_csv(saved_data_path + 'train_rl_set.csv')\n",
    "np.save(saved_data_path + 'train_total_samples.npy',train_samples)\n",
    "train_total_set.to_csv(saved_data_path + 'train_total_set.csv')\n",
    "np.save(saved_data_path + 'ui_cate.npy',[user_num, item_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8baaa0a-5033-4d5b-ad97-1bf4fed7cd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_df_list)):\n",
    "    test_df_list[i].to_csv(saved_data_path + f'test_set_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15e0fd89-af87-4a6e-a498-c44a8a0a8006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bb888-b13b-4435-aadc-73b15887212a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f9251-6fb6-4c7f-a59c-c5cb41e2ef01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7b8c449-511d-4129-8cc2-d5d6c9303e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>user_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1304, 1283, 1099, 1321, 1378, 819, 1162, 1274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1270, 1109, 93, 399, 1264, 1185, 1062, 1310, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1290, 1283, 1286, 1109, 551, 1340, 1314, 93, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1291, 961, 1270, 710, 1008, 215, 1314, 1289, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[1283, 1301, 1285, 1287, 1316, 1076, 789, 1314...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1406</td>\n",
       "      <td>[1308, 1257, 1360, 1404, 1372, 1228, 1407, 143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>[438, 1308, 1270, 1266, 1109, 153, 1267, 1257,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1408</td>\n",
       "      <td>[1284, 452, 1257, 1206, 1289, 654, 1109, 1308,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>[1315, 1220, 1362, 1360, 1221, 1369, 716, 993,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>[1304, 1283, 1279, 1154, 1301, 1282, 79, 1291,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user                                       user_history\n",
       "0        0  [1304, 1283, 1099, 1321, 1378, 819, 1162, 1274...\n",
       "1        1  [1270, 1109, 93, 399, 1264, 1185, 1062, 1310, ...\n",
       "2        2  [1290, 1283, 1286, 1109, 551, 1340, 1314, 93, ...\n",
       "3        3  [1291, 961, 1270, 710, 1008, 215, 1314, 1289, ...\n",
       "4        4  [1283, 1301, 1285, 1287, 1316, 1076, 789, 1314...\n",
       "...    ...                                                ...\n",
       "1406  1406  [1308, 1257, 1360, 1404, 1372, 1228, 1407, 143...\n",
       "1407  1407  [438, 1308, 1270, 1266, 1109, 153, 1267, 1257,...\n",
       "1408  1408  [1284, 452, 1257, 1206, 1289, 654, 1109, 1308,...\n",
       "1409  1409  [1315, 1220, 1362, 1360, 1221, 1369, 716, 993,...\n",
       "1410  1410  [1304, 1283, 1279, 1154, 1301, 1282, 79, 1291,...\n",
       "\n",
       "[1411 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rl_df = train_rl_set.groupby('user').apply(\n",
    "    lambda x: x.sort_values('timestamp')['item'].tolist()\n",
    ").reset_index(name='user_history')\n",
    "user_rl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3669aedf-7055-4606-91ed-fc8e57653f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>user_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[57, 10, 79, 117, 49, 34, 6, 133, 52, 87, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[7, 79, 47, 3, 117, 133, 120, 101, 107, 113, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[54, 39, 83, 16, 20, 109, 14, 185, 55, 18, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[7, 57, 41, 44, 12, 10, 114, 78, 107, 52, 25, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[17, 203, 205, 170, 251, 284, 289, 291, 336, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1406</td>\n",
       "      <td>[24, 13, 53, 73, 79, 12, 208, 196, 278, 303, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>[427, 73, 229, 71, 222, 552, 145, 20, 9, 291, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1408</td>\n",
       "      <td>[28, 34, 114, 203, 43, 179, 46, 192, 205, 208,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>[32, 57, 196, 192, 62, 216, 54, 271, 263, 218,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>[18, 7, 57, 50, 192, 204, 216, 172, 229, 287, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user                                       user_history\n",
       "0        0  [57, 10, 79, 117, 49, 34, 6, 133, 52, 87, 13, ...\n",
       "1        1  [7, 79, 47, 3, 117, 133, 120, 101, 107, 113, 1...\n",
       "2        2  [54, 39, 83, 16, 20, 109, 14, 185, 55, 18, 9, ...\n",
       "3        3  [7, 57, 41, 44, 12, 10, 114, 78, 107, 52, 25, ...\n",
       "4        4  [17, 203, 205, 170, 251, 284, 289, 291, 336, 3...\n",
       "...    ...                                                ...\n",
       "1406  1406  [24, 13, 53, 73, 79, 12, 208, 196, 278, 303, 3...\n",
       "1407  1407  [427, 73, 229, 71, 222, 552, 145, 20, 9, 291, ...\n",
       "1408  1408  [28, 34, 114, 203, 43, 179, 46, 192, 205, 208,...\n",
       "1409  1409  [32, 57, 196, 192, 62, 216, 54, 271, 263, 218,...\n",
       "1410  1410  [18, 7, 57, 50, 192, 204, 216, 172, 229, 287, ...\n",
       "\n",
       "[1411 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_total_df = train_total_set.groupby('user').apply(\n",
    "    lambda x: x.sort_values('timestamp')['item'].tolist()\n",
    ").reset_index(name='user_history')\n",
    "user_total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59940996",
   "metadata": {},
   "source": [
    "## Get user historical preference for training FairAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58f46442-1887-4ee4-9b58-50c631252326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def set_values_by_id(interaction_history, item_num):\n",
    "    \"\"\"\n",
    "    Convert a user's interaction history (list) into a fixed-length list where interacted items are marked as 1 and non-interacted items as 0.\n",
    "\n",
    "    Args:\n",
    "        interaction_history (list): List of interacted item IDs.\n",
    "        item_num (int): Total number of items.\n",
    "\n",
    "    Returns:\n",
    "        list: A binary list indicating interactions.\n",
    "    \"\"\"\n",
    "    # Convert interaction_history to a set for efficient membership checking\n",
    "    interaction_set = set(interaction_history)\n",
    "    return [1 if i in interaction_set else 0 for i in range(item_num)]\n",
    "\n",
    "def get_weight(warm_item_list, cold_item_list):\n",
    "    \"\"\"\n",
    "    Calculate weights for warm and cold items.\n",
    "\n",
    "    Args:\n",
    "        warm_item_list (list): List of warm item IDs.\n",
    "        cold_item_list (list): List of cold item IDs.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two numpy arrays containing weights for warm and cold items.\n",
    "    \"\"\"\n",
    "    warm_num = len(warm_item_list)\n",
    "    warm_weight = np.arange(warm_num, 0, -1)  # Weights from warm_num to 1\n",
    "\n",
    "    cold_num = len(cold_item_list)\n",
    "    if cold_num > 1:\n",
    "        cold_weight = 1 + np.arange(cold_num) * (warm_num - 1) / (cold_num - 1)\n",
    "    else:\n",
    "        cold_weight = np.array([1])\n",
    "    return warm_weight, cold_weight\n",
    "\n",
    "def get_user_hist_tgf(exp_list, warm_item_list, cold_item_list, warm_weight, cold_weight):\n",
    "    \"\"\"\n",
    "    Calculate the user's category weight difference (tgf).\n",
    "\n",
    "    Args:\n",
    "        exp_list (list): List of experience values for each item.\n",
    "        warm_item_list (list): List of warm item IDs.\n",
    "        cold_item_list (list): List of cold item IDs.\n",
    "        warm_weight (numpy array): Weights for warm items.\n",
    "        cold_weight (numpy array): Weights for cold items.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated user TGF value.\n",
    "    \"\"\"\n",
    "    if np.sum(exp_list) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Normalize the experience values\n",
    "    exp_list = exp_list / np.sum(exp_list)\n",
    "\n",
    "    # Extract experience values for warm and cold items\n",
    "    warm_exp_list = exp_list[warm_item_list]\n",
    "    cold_exp_list = exp_list[cold_item_list]\n",
    "\n",
    "    # Calculate warm and cold parts\n",
    "    warm_part = np.sum(warm_exp_list * warm_weight) / len(warm_item_list)\n",
    "    cold_part = np.sum(cold_exp_list * cold_weight) / len(cold_item_list)\n",
    "\n",
    "    # Calculate the category weight difference (TGF)\n",
    "    user_tgf = warm_part - cold_part\n",
    "    return user_tgf\n",
    "\n",
    "def cal_tgf(exp_list, warm_item_list, cold_item_list):\n",
    "    \"\"\"\n",
    "    Calculate the category weight difference (tgf).\n",
    "\n",
    "    Args:\n",
    "        exp_list (list): List of experience values for each item.\n",
    "        warm_item_list (list): List of warm item IDs.\n",
    "        cold_item_list (list): List of cold item IDs.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated TGF value.\n",
    "    \"\"\"\n",
    "    # Return 0 if exp_list is empty\n",
    "    if len(exp_list) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Normalize the experience values\n",
    "    total_exp = np.sum(exp_list)\n",
    "    if total_exp != 0:\n",
    "        exp_list = exp_list / total_exp\n",
    "\n",
    "    # Extract experience values for warm and cold items\n",
    "    warm_exp_list = [exp_list[item] for item in warm_item_list]\n",
    "    cold_exp_list = [exp_list[item] for item in cold_item_list]\n",
    "\n",
    "    # Calculate weights for warm items\n",
    "    warm_num = len(warm_exp_list)\n",
    "    warm_weight = np.arange(warm_num, 0, -1)  # Weights from warm_num to 1\n",
    "\n",
    "    # Calculate weights for cold items\n",
    "    cold_num = len(cold_exp_list)\n",
    "    if cold_num > 1:\n",
    "        cold_weight = 1 + np.arange(cold_num) * (warm_num - 1) / (cold_num - 1)\n",
    "    else:\n",
    "        cold_weight = [1]\n",
    "\n",
    "    # Calculate warm and cold parts\n",
    "    warm_part = np.sum(warm_exp_list * warm_weight) / warm_num\n",
    "    cold_part = np.sum(cold_exp_list * cold_weight) / cold_num\n",
    "\n",
    "    # Calculate the category weight difference (TGF)\n",
    "    cate_tgf = warm_part - cold_part\n",
    "    return cate_tgf\n",
    "\n",
    "def calculate_nc(input_set, target_set):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of values in the input set that appear in the target set.\n",
    "\n",
    "    Args:\n",
    "        input_set (list): Input set of values.\n",
    "        target_set (list): Target set of values.\n",
    "\n",
    "    Returns:\n",
    "        float: Proportion of values in input_set that are present in target_set.\n",
    "    \"\"\"\n",
    "    if not input_set:\n",
    "        return 0.0\n",
    "    count = len(set(input_set) & set(target_set))  # Calculate the size of the intersection\n",
    "    return count / len(input_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e59f0d4-ecc0-4061-acac-9024d2ed74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load warm and cold item lists from saved files\n",
    "warm_item_list = np.load(saved_data_path + 'warm_item_list.npy')\n",
    "cold_item_list = np.load(saved_data_path + 'cold_item_list.npy')\n",
    "\n",
    "# Convert warm_item_list and cold_item_list to NumPy arrays for efficient operations\n",
    "warm_item_list = np.array(warm_item_list)\n",
    "cold_item_list = np.array(cold_item_list)\n",
    "\n",
    "# Precompute weights for warm and cold items using the get_weight function\n",
    "warm_weight, cold_weight = get_weight(warm_item_list, cold_item_list)\n",
    "\n",
    "# Apply the set_values_by_id function to create an 'exp_list' column in the DataFrame\n",
    "# This column represents the user's interaction history as a binary list (1 for interacted, 0 for not interacted)\n",
    "user_rl_df['exp_list'] = user_rl_df['user_history'].apply(lambda x: set_values_by_id(x, config['item_num']))\n",
    "\n",
    "# Calculate the user's category weight difference (TGF) and store it in the 'hist_tgf' column\n",
    "user_rl_df['hist_tgf'] = user_rl_df['exp_list'].apply(\n",
    "    lambda x: get_user_hist_tgf(x, warm_item_list, cold_item_list, warm_weight, cold_weight)\n",
    ")\n",
    "\n",
    "# Calculate the proportion of user interactions that are with cold items (NC) and store it in 'rl_nc'\n",
    "rl_nc = user_rl_df['user_history'].apply(\n",
    "    lambda x: calculate_nc(x, cold_item_set)\n",
    ")\n",
    "\n",
    "# Add the calculated NC values to the DataFrame as a new column 'hist_nc'\n",
    "user_rl_df['hist_nc'] = rl_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73ba20f4-0eb5-4950-81f4-93e8a0843698",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_user_his_pref = user_rl_df[['user', 'user_history', 'hist_tgf', 'hist_nc']]\n",
    "rl_user_his_pref.to_csv(saved_data_path + 'rl_user_his_pref.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e98384-29b7-4987-934d-c956cd473508",
   "metadata": {},
   "source": [
    "## Get item pop for training baseline Pearson PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d9d473-d62b-4c54-97d6-394ab3333bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop_train = train_total_set.item.value_counts().reset_index()\n",
    "item_pop_train.columns = ['item', 'train_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74dc9dcd-6884-4da3-baad-66db01fc9fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item            1994\n",
       "train_counts    1218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pop_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7607966d-b58c-4b4d-bc4a-96aa46934ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>train_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>3313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>3314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>3315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>3316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item train_counts\n",
       "0      376         1218\n",
       "1      444         1207\n",
       "2       16         1206\n",
       "3      303         1196\n",
       "4      452         1190\n",
       "...    ...          ...\n",
       "3312  3312            1\n",
       "3313  3313            1\n",
       "3314  3314            1\n",
       "3315  3315            1\n",
       "3316  3316            1\n",
       "\n",
       "[3317 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_items = list(set(range(config['item_num'])) - set(train_total_set.item) )\n",
    "# len(add_items)\n",
    "add_list = []\n",
    "for i in add_items:\n",
    "    add_list.append([i, 1])\n",
    "add_pd = pd.DataFrame(add_list, columns = ['item', 'train_counts'])\n",
    "item_pop_train.columns = ['item', 'train_counts']\n",
    "item_pop_train = pd.concat([item_pop_train, add_pd])\n",
    "item_pop_train = item_pop_train.reset_index(drop = True)\n",
    "item_pop_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927d7fd4-148b-4cfe-bf3e-2c558a7719d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop_train.to_csv(saved_data_path + 'item_pop_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33740ecf-1b59-4875-b64e-4a3ac11dfead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3316"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pop_train.item.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a41743-682b-42f7-b15e-a47d007205c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1f15842",
   "metadata": {},
   "source": [
    "## Convert ID for pre-trained content embeddings for training ALDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2017ee22-4859-48b6-bc95-1047a8f6b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kuairec_id = np.load('kuairec_id_list.npy')\n",
    "kuairec_all_embed = np.load('kuairec_item_content_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "394711d4-4165-4ef7-8dd6-347305c68a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings_list = [embedding.tolist() for embedding in kuairec_all_embed]\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'item': kuairec_id,\n",
    "    'item_embedding': item_embeddings_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51372a09-d64b-41ce-ab9d-b0b52675f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_id(df, time_dict, id_column='id'):\n",
    "    \"\"\"\n",
    "    Convert the specified ID column in a Pandas DataFrame based on the provided mapping dictionary (time_dict),\n",
    "    and ensure the ID column is in integer format.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the ID column to be converted.\n",
    "        time_dict (dict): A mapping dictionary in the format {original_id: new_id}.\n",
    "        id_column (str): The name of the ID column to be converted. Defaults to 'id'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame containing only rows with IDs present in time_dict,\n",
    "                      and with the ID column converted to integer format.\n",
    "    \"\"\"\n",
    "    # Convert the ID column to integer format, coercing invalid values to NaN\n",
    "    df[id_column] = pd.to_numeric(df[id_column], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Filter the DataFrame to include only rows with IDs present in time_dict\n",
    "    df_filtered = df[df[id_column].isin(time_dict.keys())]\n",
    "\n",
    "    # Map the IDs in the filtered DataFrame using the time_dict\n",
    "    df_filtered[id_column] = df_filtered[id_column].map(time_dict)\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73724d2-eb59-49eb-89cb-007cfb23e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = convert_id(df, time_dict)\n",
    "df_new = df_new.sort_values('item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7fb20ead-8780-46ba-bef1-4ea2f0b28518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3317, 384)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kuairec_item_embedding = df_new.item_embedding.to_list()\n",
    "np.shape(kuairec_item_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "088a5046-e1de-4f95-938f-464d3775f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kuairec_item_embedding = df_new.item_embedding.to_list()\n",
    "np.shape(kuairec_item_embedding)\n",
    "np.save(saved_data_path + 'kuairec_item_embedding.npy', kuairec_item_embedding )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
